#!/usr/bin/python3

# SPDX-License-Identifier: MPL-2.0

import time
import subprocess
import os
import sys
import shutil
import re
import queue
import threading
import signal
import curses

import oc_pylib.util as util

class Command:
    args = {
        "keep" : False,
        "force" : False,
        "eda-dir" : "eda.work",
        "job-name" : "",
        "work-dir" : "",
        "suffix" : "",
        "design" : "",
        "logfile" : "",
    }
    def __init__(self, config, command_name):
        self.modified_args = {}
        self.config = config
        self.command_name = command_name
        self.target = ""

    def create_work_dir(self):
        if (not os.path.exists(self.args['eda-dir'])): # use os.path.isfile / isdir also
            os.mkdir(self.args['eda-dir'])
        if self.args['design'] == "":
            if ('top' in self.args) and (self.args['top'] != ""):
                self.args['design'] = self.args['top']
            else:
                self.args['design'] = "design" # generic, i.e. to create work dir "design_upload"
        if self.target == "":
            self.target = self.args['design']
        if self.args['work-dir'] == "":
            if self.args['job-name'] != "": self.args['work-dir'] = os.path.join(self.args['eda-dir'], self.args['job-name'])
            else:                           self.args['work-dir'] = os.path.join(self.args['eda-dir'], f"{self.target}_{self.command_name}")
        keep_file = os.path.join(self.args['work-dir'], "eda.keep")
        if (os.path.exists(self.args['work-dir'])):
            if os.path.exists(keep_file) and not self.args['force']:
                self.error(f"Cannot remove old work dir due to '{keep_file}'")
            util.info(f"Removing previous '{self.args['work-dir']}'")
            shutil.rmtree(self.args['work-dir'])
        os.mkdir(self.args['work-dir'])
        if (self.args['keep']):
            open(keep_file, 'w').close()
        return self.args['work-dir']

    def exec(self, work_dir, command_list, background=False, stop_on_error=True, quiet=False):
        if not quiet:
            util.info("exec: %s (in %s)" % (' '.join(command_list), work_dir))
        original_cwd = util.getcwd()
        os.chdir(work_dir)
        if not background:
            stdout = "" # these will be send direct to screen
            stderr = ""
            util.debug(f"About to call os.system({' '.join(command_list)})")
            return_code = os.system(" ".join(command_list)) >> 8
        elif True:
            util.debug(f"about to call subprocess.Popen({' '.join(command_list)})")
            PIPE=subprocess.PIPE
            STDOUT=subprocess.STDOUT
            proc = subprocess.Popen(command_list, stdout=PIPE, stderr=STDOUT)
            util.debug(f"about to call proc.communicate")
            stdout, stderr = proc.communicate()
            return_code = proc.returncode
            stdout = stdout.decode('utf-8') if stdout else ""
            stderr = stderr.decode('utf-8') if stderr else ""
            util.debug(f"stdout={stdout}")
            util.debug(f"stderr={stderr}")
            util.debug(f"return_code={return_code}")
        else:
            try:
                util.debug(f"about to call subprocess.check_output({' '.join(command_list)})")
                return_code = subprocess.check_output(command_list, stdout=subprocess.PIPE,stderr=subprocess.STDOUT).decode("utf-8")
                util.debug(f"subprocess.check_output result={return_code}")
            except subprocess.CalledProcessError as e:
                util.error(f"FAIL: {e.output.decode('utf-8')}")
                return "<BAD>"
            except KeyboardInterrupt as e:
                util.fancy_stop()
                util.info('EXEC: Control-C detected...')
                util.exit(-1)
            except:
                e = sys.exc_info()[0]
                util.error(f"UNKNOWN FAIL: {str(e)}")
                return "<BAD>"

        os.chdir(original_cwd)
        if return_code:
            if stop_on_error: util.error(f"exec: returned with error (return code: {return_code})")
            else            : util.debug(f"exec: returned with error (return code: {return_code})")
        else:
            util.debug(f"exec: returned without error (return code: {return_code})")
        return stderr, stdout, return_code

    def set_arg(self, key, value):
        self.args[key] = value
        self.modified_args[key] = True
        util.debug("Set arg['%s']='%s'" % (key, value))
        # we trap the writing of logfile here, because we must act immediately
        if key == "logfile": util.start_log(value)

    def process_tokens(self, tokens, process_all=True):
        first = True
        while (len(tokens) and (first or process_all)):
            first = False
            # see if it's a flag/option like --debug, --seed <n>, etc, or negating like --no-color
            m = re.match(r'^\-\-([\w\-]+)\S*', tokens[0])
            if m:
                key = m.group(1)
                new_state = True
                m = re.match(r'^no\-([\w\-]+)$', key)
                if m:
                    key = m.group(1)
                    new_state = False
                if key in self.args:
                    token = tokens.pop(0)
                    if self.args[key]==True or self.args[key]==False: # is this a true/false flag
                        if self.args[key] != new_state:
                            self.args[key] = new_state
                            self.modified_args[key] = True
                            util.debug(f"Set arg[{key}]={new_state}")
                            continue
                        else:
                            util.debug(f"Would set arg[{key}]={new_state}, but it already is")
                            continue
                    # this is an arg with a value, not a true/false flag
                    elif '=' in token:
                        # it has an "=", is it in --key="some string" form?
                        m = re.match(r'^[^\=]+\=(\"[^\"]*\")$', token)
                        if m:
                            value = m.group(1)
                            self.set_arg(key, value)
                            continue
                        # it has an "=", is it in --key=value form?
                        m = re.match(r'^[^\=]+\=(\S+)$', token)
                        if m:
                            value = m.group(1)
                            self.set_arg(key, value)
                            continue
                    elif len(tokens): # this is an arg with a value, not a true/false flag
                        value = tokens.pop(0)
                        self.set_arg(key, value)
                        continue
                    else:
                        util.error("Need a value after --%s" % (key))
            # we were unable to figure out what this command line token is for...
            if process_all:          util.error(f"Didn't understand command token: '{tokens[0]}' in {self.command_name} context")
            else:                    return False # if we aren't trying to process_all, the caller hopefully can take it
        return True

    def do_it(self):
        util.error(f"No tool bound to command '{self.command_name}', you probably need to setup tool, or use '--tool <name>'")

    def help(self):
        util.info(f"Generic help (from class Command):")
        for k in sorted(self.args.keys()):
            v = self.args[k]
            if type(v) == bool :
                util.info(f"   {k:20} : boolean    : {v}")
            elif type(v) == int:
                util.info(f"   {k:20} : integer    : {v}")
            elif type(v) == list:
                util.info(f"   {k:20} : list       : {v}")
            elif type(v) == str:
                util.info(f"   {k:20} : string     : '{v}'")
            else:
                util.info(f"   {k:20} : <unknown>  : {v}")

class CommandDesign(Command):
    def __init__(self, config, command_name):
        Command.__init__(self, config, command_name)
        self.args['seed'] = int(time.time())
        self.args['top'] = ""
        self.args['all_sv'] = False
        self.defines = { }
        self.incdirs = []
        self.files = { }
        self.targets = { }
        self.files_v = []
        self.files_sv = []
        self.files_vhd = []
        oc_root = util.get_oc_root()
        if oc_root: self.incdirs.append(oc_root)
        for (d,v) in config['defines'].items():
            self.defines[d] = v

    def get_top_name(self, name):
        return os.path.splitext(os.path.basename(name))[0]

    def process_plusarg(self, plusarg):
        m = re.match(r'^\+define\+(\w+)$', plusarg)
        if m:
            self.defines[m.group(1)] = None
            util.debug(f"Defined {m.group(1)}")
            return
        m = re.match(r'^\+define\+(\w+)\=(\S+)$', plusarg)
        if m:
            self.defines[m.group(1)] = m.group(2)
            util.debug(f"Defined {m.group(1)}={m.group(2)}")
            return
        m = re.match(r'^\+incdir\+(\S+)$', plusarg)
        if m:
            incdir = m.group(1)
            self.incdirs.append(os.path.abspath(incdir))
            util.debug(f"Added include dir '{incdir}'")
            return
        util.error(f"Didn't understand +plusarg: '{plusarg}'")

    def resolve_target(self, target, no_recursion=False):
        util.debug("Entered resolve_target(%s)" % (target))
        self.target = target
        m = re.match(r'.*\/([\w\_]+)$', self.target)
        if m: self.target = m.group(1)
        targets_todo = [ target ]
        targets_dict = { target : None }
        found_any_target = False
        while len(targets_todo):
            found_this_target = False
            t = targets_todo.pop(0)
            util.debug("Starting to resolve target '%s'" % (t))
            t_path, t_node = os.path.split(t)
            deps_file = os.path.join(t_path, "DEPS")
            # yes, we reparse the DEPS file for every target we search for.  sometimes hitting a target causes
            # side effects (like defining things) which then could affect DEPS.  TBD is the specific case where one
            # target is pulled in multiple times and the defines/etc are different; it will just get read in first
            # time, but the same can be said for file lists in general (we don't support re-reading files with
            # different defines set, although this can always be done using `include in the sources)
            # In general it's common to run into this "race" condition, i.e.  lib_synchronizer with two conditional
            # implementations, we read it in before "GATE_SIM" is set by the top level target, because we pulled
            # in a lib element causing us to read lib/DEPS (we had more than one thing on command line for example).
            # so we don't worry about spending a few extra cycles and just doing it the "simple, inefficient" way.
            if os.path.isfile(deps_file):
                f = open( deps_file, 'r' )
                util.debug("Opened '%s'" % (deps_file))
                in_dep = False
                line_number = 0
                for line in f:
                    line_number += 1
                    # clear out comments
                    m = re.match(r'^([^\#]*)\#.*$', line)
                    if m:
                        line = m.group(1)
                    # look for the declaration of a target, which looks like "<target> : [dep .. dep] \n [dep .. dep] \n"
                    m = re.match(r'^\s*(\w+)\s*\:(.*)$', line)
                    if m:
                        if in_dep:
                            util.debug("Done with %s at %s:%d" % (t, deps_file, line_number-1))
                            break # stop looking through this DEP file, we cannot appear more than once
                        elif m.group(1) == t_node:
                            in_dep = True # we have found our DEP!
                            found_this_target = True
                            found_any_target = True
                            line = m.group(2) # we trim down line and let lower code parse the rest
                            util.debug("Found %s at %s:%d" % (t, deps_file, line_number))
                            if no_recursion: return True
                        else:
                            continue # it's the start of a DEP, but not ours
                    else:
                        if not in_dep:
                            continue # move on to next line if we aren't currently in the DEP

                    # at this point we are processing a line from our DEP, but we may do some conversions on it
                    for dep_sub in self.config['dep_sub']:
                        line = re.sub(dep_sub[0], dep_sub[1], line)
                        m = re.search(r'\$(\w+)', line)
                        while m: # do we have any variables to substitute?
                            if m.group(1) in self.config['vars']:
                                line = re.sub(r'\$%s' % (m.group(1)), self.config['vars'][m.group(1)], line)
                            m = re.search(r'\$\w+', line)

                    # check for conditional inclusions based on defines
                    m = re.match(r'^\s*(\w+)\s+\?([^\:]*)\s*(\:)?\s*(.*)*$', line)
                    if m:
                        v = m.group(1)
                        l1 = m.group(2)
                        l2 = m.group(3)
                        line = l1 if v in self.defines else l2
                        if line == None: line = ""

                    # check for setting an EDA argument
                    m = re.match(r'^\s*\-\-([\w\-]+)\s*', line)
                    if m:
                        Command.process_tokens(self, line.split())
                        continue

                    for dep in line.split():
                        # see if this is a generated source file
                        m = re.match(r'^\s*([\w\.]+)\@(\S+)\s*$', dep)
                        if m:
                            source_file = m.group(1)
                            exec_csv = m.group(2)
                            exec_list = exec_csv.split(",")
                            util.info("Generating %s via '%s'" % (source_file, " ".join(exec_list)))
                            self.exec(t_path, exec_list)
                            if os.path.exists(os.path.join(t_path, source_file)):
                                util.debug("Done generating %s via '%s'" % (os.path.join(t_path, source_file), " ".join(exec_list)))
                                self.add_file(os.path.join(t_path, source_file))
                                continue
                            else:
                                util.error("Failed to generate %s via '%s'" % (source_file, " ".join(exec_list)))
                        # see if there's any conditionally included code

                        # check for a Verilog style plusarg, which are supported under targets
                        m = re.match(r'^\+(define|incdir)\+\S+$', dep)
                        if m:
                            util.debug("Got plusarg %s for target %s at %s:%d" % (dep, t, deps_file, line_number))
                            self.process_plusarg(dep)
                            continue

                        # this dep hasn't been dealt with above, which are rare things, do it the normal way
                        dep_path = os.path.join(t_path, dep)
                        util.debug("Got dep %s for target %s at %s:%d" % (dep_path, t, deps_file, line_number))
                        if dep_path in targets_dict:
                            util.debug(" - already processed, skipping")
                            continue
                        targets_dict[dep_path] = None
                        if os.path.exists(dep_path):
                            util.debug(" - raw file, adding to file lists")
                            self.add_file(dep_path)
                        else:
                            util.debug(" - a target needing to be resolved, adding to queue")
                            targets_todo.append(dep_path)

            if not found_this_target:
                util.debug("Haven't been able to resolve %s via DEPS" % (t))
                for e in [ '.sv', '.v', '.vhd' ]:
                    try_file = t+e
                    util.debug("Looking for %s" % (try_file))
                    if os.path.exists(try_file):
                        self.add_file(try_file)
                        found_this_target = True
                        found_any_target = True
                        break # move on to the next target
                if not found_this_target: # if STILL not found_this_target...
                    util.error("Unable to resolve target '%s'" % (t))

        # if we've found any target since being called, it means we found the one we were called for
        return found_any_target

    def insert_file_in_order(self, file_list, filename, order=None):
        if order==None:
            order = 0 # default to zero
            for file_order in self.config['file_order']:
                m = re.match(file_order[0], filename)
                if m: order=file_order[1] # if we match the regex, take order from the rule
        # we now have an order, if it's >= 0, we start looking from the end
        if order >= 0:
            insert_position = len(file_list)
            while ((insert_position > 0) and (self.files[file_list[insert_position-1]] > order)):
                # the file just before our insert position has a higher order, need to be earlier
                insert_position -= 1
        # we have a negative order, start looking at the front
        else:
            insert_position = 0
            while ((insert_position < len(file_list)) and (self.files[file_list[insert_position]] < order)):
                # the file currently at our insert position has a lower order, need to be later
                insert_position += 1
        file_list.insert(insert_position, filename)
        self.files[filename] = order
        return order

    def add_file(self, filename):
        file_base, file_ext = os.path.splitext(filename)
        file_abspath = os.path.abspath(filename)
        if file_abspath in self.files:
            util.debug("Not adding file %s, already have it" % (file_abspath))
            return
        if file_ext == '.v' and not self.args['all_sv']:
            order = self.insert_file_in_order(self.files_v, file_abspath)
            util.debug("Added Verilog file %s as %s (order=%d)" % (filename, file_abspath, order))
        elif file_ext == '.sv' or (file_ext == '.v' and self.args['all_sv']):
            order = self.insert_file_in_order(self.files_sv, file_abspath)
            util.debug("Added SystemVerilog file %s as %s (order=%d)" % (filename, file_abspath, order))
        elif file_ext == '.vhd':
            order = self.insert_file_in_order(self.files_vhd, file_abspath)
            util.debug("Added VHDL file %s as %s (order=%d)" % (filename, file_abspath, order))
        return file_abspath

    def process_tokens(self, tokens, process_all=True):
        first = True
        while (first or (len(tokens) and process_all)):
            first = False
            # see if it's a flag/option like --debug, --seed <n>, etc
            if Command.process_tokens(self, tokens, process_all=False):
                continue
            # see if it's a CommandDesign specific option
            m = re.match(r'^\+(define|incdir)\+\S+$', tokens[0])
            if m:
                self.process_plusarg(tokens[0])
                tokens.pop(0)
                continue
            # by this point hopefully this is a target ... is it a simple filename?
            if os.path.exists(tokens[0]):
                file_abspath = self.add_file(tokens[0])
                if self.args['top'] == "":
                    # if we haven't yet been given a top, or inferred one, we take the first one we get
                    self.args['top'] = self.get_top_name(file_abspath)
                    self.args['top-path'] = file_abspath
                    util.info(f"Inferred --top {self.args['top']} {file_abspath}")
                tokens.pop(0)
                continue
            # we appear to be dealing with a target name which needs to be resolved (usually recursively)
            if tokens[0][0] == os.sep:
                target_name = tokens[0] # if it's absolute path, don't prepend anythng
            else:
                target_name = os.path.join(".", tokens[0]) # prepend ./so that we always have a <path>/<file>
            if self.resolve_target(target_name):
                if self.args['top'] == "":
                    # if we haven't yet been given a top, or inferred one, we take the first one we get
                    self.args['top'] = self.get_top_name(target_name)
                    self.args['top-path'] = target_name
                    util.info(f"Inferred --top {self.args['top']} {target_name}")
                tokens.pop(0)
                continue
            # we were unable to figure out what this command line token is for...
            if process_all:  util.error("Didn't understand command token: '%s' in CommandDesign" % (tokens[0]))
            else:            return False # if we aren't trying to process_all, the caller hopefully can take it

        self.defines['OC_SEED'] = f"{self.args['seed']}"
        self.defines['OC_ROOT'] = f"\"{oc_root}\""

class CommandSim(CommandDesign):

    def __init__(self, config):
        CommandDesign.__init__(self, config, "sim")
        self.args['waves'] = False
        self.args['waves-start'] = 0
        self.args['pass-pattern'] = ""
        # the following is used to enable "eda elab" (in general we will give certain tools option to stop early: lint etc)
        self.stop_after_compile = False

    def process_tokens(self, tokens, process_all=True):
        self.defines['SIMULATION'] = None
        CommandDesign.process_tokens(self, tokens, process_all)
        # add defines for this job type
        if (self.args['top'] != ""):
            # create our work dir
            self.create_work_dir()
            self.do_it()

class CommandElab(CommandSim):
    def __init__(self, config):
        CommandSim.__init__(self, config)
        # add args specific to this simulator
        self.stop_after_compile = True

class CommandSynth(CommandDesign):
    def __init__(self, config):
        CommandDesign.__init__(self, config, "synth")
        self.args['flatten-all'] = False
        self.args['flatten-none'] = False
        self.args['clock-ns'] = 5 # 200Mhz
        self.args['idelay-ns'] = 2
        self.args['odelay-ns'] = 2

    def process_tokens(self, tokens, process_all=True):
        self.defines['SYNTHESIS'] = None
        CommandDesign.process_tokens(self, tokens, process_all)
        # add defines for this job type
        if (self.args['top'] != ""):
            # create our work dir
            self.create_work_dir()
            self.do_it()

class CommandProj(CommandDesign):
    def __init__(self, config):
        CommandDesign.__init__(self, config, "proj")

    def process_tokens(self, tokens, process_all=True):
        CommandDesign.process_tokens(self, tokens, process_all)
        # add defines for this job type
        if (self.args['top'] != ""):
            # create our work dir
            self.create_work_dir()
            self.do_it()

class CommandBuild(CommandDesign):
    def __init__(self, config):
        CommandDesign.__init__(self, config, "build")
        self.args['build-script'] = "build.tcl"

    def process_tokens(self, tokens, process_all=True):
        CommandDesign.process_tokens(self, tokens, process_all)
        # add defines for this job type
        if (self.args['top'] != ""):
            # create our work dir
            self.create_work_dir()
            self.do_it()

_threads_start = 0
_threads_done = 0

class CommandParallelWorker(threading.Thread):
    def __init__(self, n, work_queue, done_queue):
        threading.Thread.__init__(self)
        self.n = n
        self.work_queue = work_queue
        self.done_queue = done_queue
        self.stop_request = False
        self.job_name = ""
        self.proc = None
        self.pid = None
        self.last_timer_debug = 0
        util.debug(f"WORKER_{n}: START")

    def run(self):
        global _threads_start
        global _threads_done
        while True:
            # Get the work from the queue and expand the tuple
            i, command_list, job_name, work_dir = self.work_queue.get()
            self.job_name = job_name
            try:
                util.debug(f"WORKER_{self.n}: Running job {i}: {job_name}")
                PIPE=subprocess.PIPE
                STDOUT=subprocess.STDOUT
                util.debug(f"WORKER_{self.n}: Calling Popen")
                proc = subprocess.Popen(command_list, stdout=PIPE, stderr=STDOUT)
                self.proc = proc
                util.debug(f"WORKER_{self.n}: Opened process, PID={proc.pid}")
                self.pid = proc.pid
                _threads_start += 1
                while proc.returncode == None:
                    try:
                        if (time.time() - self.last_timer_debug) > 10:
                            util.debug(f"WORKER_{self.n}: Calling proc.communicate")
                        stdout, stderr = proc.communicate(timeout=0.5)
                        util.debug(f"WORKER_{self.n}: got: \n*** stdout:\n{stdout}\n*** stderr:{stderr}")
                    except subprocess.TimeoutExpired:
                        if (time.time() - self.last_timer_debug) > 10:
                            util.debug(f"WORKER_{self.n}: Timer expired, stop_request={self.stop_request}")
                            self.last_timer_debug = time.time()
                        pass
                    if self.stop_request:
                        util.debug(f"WORKER_{self.n}: got stop request, issuing SIGINT")
                        proc.send_signal(signal.SIGINT)
                        util.debug(f"WORKER_{self.n}: got stop request, calling proc.wait")
                        proc.wait()
                    if False and self.stop_request:
                        util.debug(f"WORKER_{self.n}: got stop request, issuing proc.terminate")
                        proc.terminate()
                        util.debug(f"WORKER_{self.n}: proc poll returns is now {proc.poll()}")
                        try:
                            util.debug(f"WORKER_{self.n}: Calling proc.communicate")
                            stdout, stderr = proc.communicate(timeout=0.2) # for completeness, in case we ever pipe/search stdout/stderr
                            util.debug(f"WORKER_{self.n}: got: \n*** stdout:\n{stdout}\n*** stderr:{stderr}")
                        except subprocess.TimeoutExpired:
                            util.debug(f"WORKER_{self.n}: timeout waiting for comminicate after terminate")
                        except:
                            pass
                        util.debug(f"WORKER_{self.n}: proc poll returns is now {proc.poll()}")

                util.debug(f"WORKER_{self.n}: -- out of while loop")
                self.pid = None
                self.proc = None
                self.job_name = "<idle>"
                util.debug(f"WORKER_{self.n}: proc poll returns is now {proc.poll()}")
                try:
                    util.debug(f"WORKER_{self.n}: Calling proc.communicate one last time")
                    stdout, stderr = proc.communicate(timeout=0.1) # for completeness, in case we ever pipe/search stdout/stderr
                    util.debug(f"WORKER_{self.n}: got: \n*** stdout:\n{stdout}\n*** stderr:{stderr}")
                except subprocess.TimeoutExpired:
                    util.debug(f"WORKER_{self.n}: timeout waiting for communicate after loop?")
                except:
                    pass
                return_code = proc.poll()
                util.debug(f"WORKER_{self.n}: Finished job {i}: {job_name} with return code {return_code}")
                self.done_queue.put((i, job_name, return_code))
            finally:
                util.debug(f"WORKER_{self.n}: -- in finally block")
                self.work_queue.task_done()
                _threads_done += 1

tools_loaded = []

class CommandParallel(Command):
    def __init__(self, config, command_name):
        Command.__init__(self, config, command_name)
        self.args['parallel'] = 1
        self.worker_threads = []

    def __del__(self):
        util.debug(f"In Command.__del__, threads done/started: {_threads_done}/{_threads_start}")
        if _threads_start == _threads_done:
            return
        util.warning(f"Need to shut down {_threads_start-_threads_done} worker threads...")
        for w in self.worker_threads:
            if w.proc:
                util.warning(f"Requesting stop of PID {w.pid}: {w.job_name}")
                w.stop_request = True
        for i in range(10):
            util.debug(f"Threads done/started: {_threads_done}/{_threads_start}")
            if _threads_start == _threads_done:
                util.info(f"All threads done")
                return
            time.sleep(1)
        subprocess.Popen(['stty', 'sane']).wait()
        util.debug(f"Scanning workers again")
        for w in self.worker_threads:
            if w.proc:
                util.info(f"need to SIGINT WORKER_{w.n}, may need manual cleanup, check 'ps'")
                if w.pid:
                    os.kill(w.pid, signal.SIGINT)
        for i in range(5):
            util.debug(f"Threads done/started: {_threads_done}/{_threads_start}")
            if _threads_start == _threads_done:
                util.info(f"All threads done")
                return
            time.sleep(1)
        subprocess.Popen(['stty', 'sane']).wait()
        util.debug(f"Scanning workers again")
        for w in self.worker_threads:
            if w.proc:
                util.info(f"need to TERM WORKER_{w.n}, probably needs manual cleanup, check 'ps'")
                if w.pid:
                    os.kill(w.pid, signal.SIGTERM)
        for i in range(5):
            util.debug(f"Threads done/started: {_threads_done}/{_threads_start}")
            if _threads_start == _threads_done:
                util.info(f"All threads done")
                return
            time.sleep(1)
        subprocess.Popen(['stty', 'sane']).wait()
        util.debug(f"Scanning workers again")
        for w in self.worker_threads:
            if w.proc:
                util.info(f"need to KILL WORKER_{w.n}, probably needs manual cleanup, check 'ps'")
                if w.pid:
                    os.kill(w.pid, signal.SIGKILL)
        util.stop_log()
        subprocess.Popen(['stty', 'sane']).wait()

    def run_jobs(self, command):
        # this is where we actually run the jobs.  it's a messy piece of code and prob could use refactoring
        # but the goal was to share as much as possible (job start, end, pass/fail judgement, etc) while
        # supporting various mode combinations (parallel mode, verbose mode, fancy mode, etc) and keeping the
        # UI output functional and awesome sauce

        # walk targets to find the longest name, for display reasons
        longest_job_name = 0
        total_jobs = len(self.jobs)
        for i in range(total_jobs):
            l = len(self.jobs[i]['name'])
            if l>longest_job_name: longest_job_name = l

        run_parallel = self.args['parallel'] > 1

        # figure out the width to print various numbers
        jobs_digits = len(f"{total_jobs}")
        jobs_fmt = "%%%dd" % jobs_digits # ugh, for printing out a number with N digits

        # run the jobs!
        running_jobs = {}
        passed_jobs = []
        failed_jobs = []
        workers = []
        jobs_complete = 0
        jobs_launched = 0
        num_parallel = min(len(self.jobs), self.args['parallel'])
        # 16 should really be the size of window or ?
        (columns,lines) = shutil.get_terminal_size()
        # we will enter fancy mode if we are parallel and we can leave 6 lines of regular scrolling output
        fancy_mode = util.args['fancy'] and (num_parallel > 1) and (num_parallel <= (lines-6))
        multi_cwd = util.getcwd()+os.sep

        if run_parallel:
            # we are doing this multi-threaded
            util.info(f"Parallel: Running multi-threaded, starting {num_parallel} workers")
            work_queue = queue.Queue()
            done_queue = queue.Queue()
            for x in range(num_parallel):
                worker = CommandParallelWorker(x, work_queue, done_queue)
                # Setting daemon to True will let the main thread exit even though the workers are blocking
                worker.daemon = True
                worker.start()
                self.worker_threads.append(worker)
                workers.append(x)
            if fancy_mode:
                # in fancy mode, we will take the bottom num_parallel lines to show state of workers
                util.fancy_start(fancy_lines=num_parallel)
                for x in range(num_parallel):
                    util.fancy_print(f"Starting worker {x}", x)

        while len(self.jobs) or len(running_jobs.items()):
            job_done = False
            job_done_quiet = False
            anything_done = False

            def sprint_job_line(job_number=0, job_name="", final=False, hide_stats=False):
                return (f"INFO: [EDA] " +
                        util.string_or_space(f"[job {jobs_fmt%job_number}/{jobs_fmt%total_jobs} ", final) +
                        util.string_or_space(f"| pass ", hide_stats or final) +
                        util.string_or_space(f"{jobs_fmt%len(passed_jobs)}/{jobs_fmt%jobs_complete} ", hide_stats) +
                        util.string_or_space(f"@ {(100*(jobs_complete))/total_jobs:5.1f}%", hide_stats or final) +
                        util.string_or_space(f"] ", final) +
                        f"{command} {(job_name+' ').ljust(longest_job_name+3,'.')}")

            # for any kind of run (parallel or not, fancy or not, verbose or not) ... can we launch a job?
            if len(self.jobs) and (len(running_jobs.items()) < num_parallel):
                # we are launching a job
                jobs_launched += 1
                anything_done = True
                job = self.jobs.pop(0)
                if job['name'].startswith(multi_cwd): job['name'] = job['name'][len(multi_cwd):]
                # in all but fancy mode, we will print this text at the launch of a job.  It may get a newline below
                job_text = sprint_job_line(jobs_launched, job['name'], hide_stats=run_parallel)
                command_list = job['command_list']

                if run_parallel:
                    # multithreaded job launch: add to queue
                    worker = workers.pop(0) # we don't actually know which thread will pick up, but GUI will be consistent
                    running_jobs[str(jobs_launched)] = { 'name' : job['name'],
                                                         'number' : jobs_launched,
                                                         'worker' : worker,
                                                         'start_time' : time.time(),
                                                         'update_time' : time.time()}
                    work_queue.put((jobs_launched, command_list, job['name'], cwd))
                    suffix = "<START>"
                    if fancy_mode:
                        util.fancy_print(job_text+suffix, worker)
                    else:
                        # if we aren't in fancy mode, we will print a START line, periodic RUNNING lines, and PASS/FAIL line per-job
                        if len(failed_jobs): util.print_orange(job_text+util.string_yellow+suffix)
                        else:                util.print_yellow(job_text+util.string_yellow+suffix)
                else:
                    # single-threaded job launch, we are going to print out job info as we start each job... no newline
                    # since non-verbose silences the job and prints only <PASS>/<FAIL> after the trailing "..." we leave here
                    if len(failed_jobs): util.print_orange(job_text, end="")
                    else:                util.print_yellow(job_text, end="")
                    job_done_number = jobs_launched
                    job_done_name = job['name']
                    job_start_time = time.time()
                    if util.args['verbose']:
                        # previous status line gets a \n, then job is run passing stdout/err, then print 'job_text' again with pass/fail
                        util.print_green("")
                        # run job, sending output to the console
                        _, _, job_done_return_code = self.exec(cwd, command_list, background=False, stop_on_error=False, quiet=False)
                        # reprint the job text previously printed before running job(and given "\n" after the trailing "...")
                        #job_done_text = job_text
                    else:
                        # run job, swallowing output (hope you have a logfile)
                        _, _, job_done_return_code = self.exec(cwd, command_list, background=True, stop_on_error=False, quiet=True)
                        job_done_quiet = True # in this case, we have the job start text (trailing "...", no newline) printed
                    job_done = True
                    job_done_run_time = time.time() - job_start_time

            if run_parallel:
                # parallel run, check for completed job
                if done_queue.qsize():
                    # we're collecting a finished job from a worker thread.  note we will only reap one job per iter of the big
                    # loop, so as to share job completion code at the bottom
                    anything_done = True
                    job_done = True
                    job_done_number, job_done_name, job_done_return_code = done_queue.get()
                    t = running_jobs[str(job_done_number)]
                    # in fancy mode, we need to clear the worker line related to this job.
                    if fancy_mode:
                        util.fancy_print(f"INFO: [EDA] Parallel: Worker Idle ...", t['worker'])
                    job_done_run_time = time.time() - t['start_time']
                    util.debug(f"removing job #{job_done_number} from running jobs")
                    del running_jobs[str(job_done_number)]
                    workers.append(t['worker'])

            if run_parallel:
                # parallel run, update the UI on job status
                for _,t in running_jobs.items():
                    if (fancy_mode or (time.time() - t['update_time']) > 30):
                        t['update_time'] = time.time()
                        job_text = sprint_job_line(t['number'], t['name'], hide_stats=True)
                        suffix = f"<RUNNING: {util.sprint_time(time.time() - t['start_time'])}>"
                        if fancy_mode:
                            util.fancy_print(f"{job_text}{suffix}", t['worker'])
                        else:
                            if len(failed_jobs): util.print_orange(job_text+util.string_yellow+suffix)
                            else:                util.print_yellow(job_text+util.string_yellow+suffix)

            # shared job completion code
            # single or multi-threaded, we can arrive here to harvest <= 1 jobs, and need {job, return_code} valid, and
            # we expect the start of a status line to have been printed, ready for pass/fail
            if job_done:
                jobs_complete += 1
                if (job_done_return_code):
                    # embed the color code, to change color of pass/fail during the util.print_orange/yellow below
                    suffix = f"{util.string_red}<FAIL: {util.sprint_time(job_done_run_time)}>"
                    failed_jobs.append(job_done_name)
                else:
                    suffix = f"{util.string_green}<PASS: {util.sprint_time(job_done_run_time)}>"
                    passed_jobs.append(job_done_name)
                # we want to print in one shot, because in fancy modes that's all that we're allowed
                job_done_text = "" if job_done_quiet else sprint_job_line(job_done_number, job_done_name)
                if len(failed_jobs): util.print_orange(f"{job_done_text}{suffix}")
                else:                util.print_yellow(f"{job_done_text}{suffix}")

            if not anything_done:
                time.sleep(0.25) # if nothing happens for an iteration, chill out a bit

        if total_jobs:
            emoji = "< :) >" if (len(passed_jobs) == total_jobs) else "< :( >"
            util.info(sprint_job_line(final=True,job_name="jobs passed")+emoji, start="")
        else:
            util.info(f"Parallel: <No jobs found>")
        util.fancy_stop()


class CommandMulti(CommandParallel):
    def __init__(self, config):
        CommandParallel.__init__(self, config, "multi")

    def resolve_target(self, base_path, target, command, level=0):
        util.debug(f"ENTER RESOLVE_TARGET L{level} base_path={base_path}, target={target}, command={command}")
        target_path_parts = target.split("/")
        if len(target_path_parts) == 1:
            util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path}, {target} is a single-part target, look for matches in here")
            deps_file = os.path.join(base_path, "DEPS")
            target_pattern = "^"+target_path_parts.pop(0)+"$"
            target_pattern = target_pattern.replace("*", "[^\/]*")
            util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path}, target_pattern={target_pattern}")
            if os.path.isfile(deps_file):
                f = open( deps_file, 'r' )
                util.debug(f"RESOLVE_TARGET L{level}: Opened '{deps_file}'")
                line_number = 0
                for line in f:
                    line_number += 1
                    # look for a pragma before clearing comments
                    m = re.match(r'^([^\#]*)\#\s*eda_multi\s+ignore\s+(\S*).*$', line)
                    if m:
                        ignore_target = m.group(1)
                        ignore_command = m.group(2)
                        if (ignore_command == command) or (ignore_command == "*"):
                            if ignore_target == "":
                                util.debug(f"RESOLVE_TARGET L{level}: ignoring whole file {deps_file} due to {line} @ {line_number}")
                                break
                            else:
                                util.debug(f"RESOLVE_TARGET L{level}: ignoring one line: {line}")
                                continue

                    # clear out comments
                    m = re.match(r'^([^\#]*)\#.*$', line)
                    if m:
                        line = m.group(1)
                    # look for the declaration of a target, which looks like "<target> : [dep .. dep] \n [dep .. dep] \n"
                    m = re.match(r'^\s*(\w+)\s*\:(.*)$', line)
                    if m:
                        dep_target = m.group(1)
                        m = re.match(target_pattern, dep_target)
                        if m:
                            util.debug(f"RESOLVE_TARGET L{level}: Found dep {dep_target} matching target pattern {target_pattern}")
                            self.targets.append(os.path.join(base_path, dep_target))
        else:
            # let's look at the first part of the multi-part target path, which should be a dir
            part = target_path_parts.pop(0)
            if part == ".":
                # just reprocess this directory (matches "./some/path" and retries as "some/path")
                util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path}, processing {part}, recursing here")
                self.resolve_target(base_path, os.path.sep.join(target_path_parts), command, level+1)
            elif part == "...":
                util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path}, processing {part}, recursing to check here")
                # first we check this dir: {"<base>",".../target"} should match "target" in <base>, so we call {"<base>","target"}
                self.resolve_target(base_path, os.path.sep.join(target_path_parts), command, level+1)
                # now we find all dirs in <base> ...
                util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path}, processing {part}, looking through dirs...")
                wtg = os.listdir(base_path)
                for e in os.listdir(base_path):
                    util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path},e={e},isdir={os.path.isdir(os.path.join(base_path,e))}")
                    if os.path.isdir(os.path.join(base_path,e)):
                        util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path}, processing {part}, recursing into {e}")
                        self.resolve_target(os.path.join(base_path,e), target, command, level+1)
            elif part.startswith("."):
                util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path}, processing {part}, skipping hidden")
            elif part == self.args['eda-dir']:
                util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path}, processing {part}, skipping eda.dir")
            elif os.path.isdir(os.path.join(base_path, part)):
                # reprocess in a lower directory (matches "some/...", enters "some/", and retries "...")
                util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path}, processing {part}, recursing down")
                self.resolve_target(os.path.join(base_path, part), os.path.sep.join(target_path_parts), command, level+1)
            elif part == "*":
                # descend into every directory, we only go in if there's a DEPS though
                util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path}, processing {part}, looking through dirs...")
                for e in os.listdir(base_path):
                    util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path},e={e}")
                    if os.path.isdir(e):
                        util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path},looking for ={os.path.join(base_path,e,'DEPS')}")
                        if os.path.isfile(os.path.join(base_path,e,"DEPS")):
                            self.resolve_target(os.path.join(base_path,e), os.path.sep.join(target_path_parts), command, level+1)
            else:
                util.debug(f"RESOLVE_TARGET L{level}: base_path={base_path}, processing {part} ... but not sure what to do with it?")

    def process_tokens(self, tokens, process_all=True):
        # multi is special in the way it handles tokens, due to most of them being processed by a sub instance
        arg_tokens = [] # these are the tokens we will pass to the child eda processes
        command = ""
        target_globs = []
        arg_tokens_mode = False # once we see one arg starting with "-" or "+", they all go to the sub process
        parallelism = 1
        while len(tokens):
            token = tokens.pop(0)
            if token in config['command_handler']:
                if (command == ""):
                    command = token
                    continue
            if token == "--parallel":
                v = tokens.pop(0)
                if ((not v.isdigit()) or (int(v) < 1) or (int(v) > 256)):
                    util.error("Need an integer between 1 and 256 after --parallel")
                self.args['parallel'] = int(v)
                continue
            if arg_tokens_mode or token.startswith("-") or token.startswith("+"):
                arg_tokens.append(token)
                arg_tokens_mode == True
                continue
            target_globs.append(token)
        if command == "": util.error(f"Didn't get a command after 'multi'!")

        # now we need to expand the target list
        util.debug(f"Multi: command: '{command}'")
        util.debug(f"Multi: targets: {target_globs}")
        util.debug(f"Multi: options: {arg_tokens}")
        self.targets = []
        cwd = util.getcwd()
        for t in target_globs:
            self.resolve_target(cwd, t, command)
        util.info(f"Multi: Expanded {target_globs} to {len(self.targets)} {command} targets")
        util.info(f"Multi: About to run: ", end="")
        if len(self.targets) > 20:
            for i in range(10):
                util.info(f"{self.targets[i]} , ", start="", end="")
            util.info(f"... ", start="", end="")
            for i in range(len(self.targets)-10, len(self.targets)):
                util.info(f" , {self.targets[i]}", start="", end="")
            util.info("", start="")
        else:
            util.info(" , ".join(self.targets), start="")
        util.debug(f"Multi: converting list of targets into list of jobs")
        self.jobs = []
        for target in self.targets:
            self.jobs.append({'name' : target,
                              'command_list' : (['python3', os.path.realpath(__file__), command, target] + arg_tokens)})
        self.run_jobs(command)


class CommandSweep(CommandDesign, CommandParallel):
    def __init__(self, config):
        CommandDesign.__init__(self, config, "sweep")
        CommandParallel.__init__(self, config, "sweep")

    def process_tokens(self, tokens, process_all=True):
        # multi is special in the way it handles tokens, due to most of them being processed by a sub instance
        sweep_axis_list = []
        command = ""
        target = ""
        arg_tokens = []
        while len(tokens):
            token = tokens.pop(0)
            if token in config['command_handler']:
                if command == "":
                    command = token
                    continue
            if token == "--parallel":
                v = tokens.pop(0)
                if ((not v.isdigit()) or (int(v) < 1) or (int(v) > 256)):
                    util.error("Need an integer between 1 and 256 after --parallel")
                self.args['parallel'] = int(v)
                continue
            m = re.match(r'(\S+)\=\((\d+)\,(\d+)(,(\d+))?\)', token)
            if m:
                sweep_axis = { 'key' : m.group(1),
                               'from' : float(m.group(2)),
                               'to' : float(m.group(3)),
                               'step' : float(m.group(5)) if m.group(4) != None else 1.0 }
                util.debug(f"Sweep axis: {sweep_axis['key']} = {sweep_axis['from']} to {sweep_axis['to']} step {sweep_axis['step']}")
                sweep_axis_list.append(sweep_axis)
                continue
            if token.startswith('--') or token.startswith('+'):
                arg_tokens.append(token)
                continue
            if self.resolve_target(token, no_recursion=True):
                if target != "":
                    util.error(f"Sweep can only take one target, already got {target}, now getting {token}")
                target = token
                continue
            util.error(f"Sweep doesn't know what to do with arg '{token}'")
        if command == "": util.error(f"Didn't get a command after 'sweep'!")

        # now we need to expand the target list
        util.debug(f"Sweep: command:    '{command}'")
        util.debug(f"Sweep: target:     '{target}'")
        util.debug(f"Sweep: arg_tokens: '{arg_tokens}'")

        # now create the list of jobs, support one axis
        self.jobs = []
        self.expand_sweep_axis(command, target, arg_tokens, sweep_axis_list)
        self.run_jobs(command)

    def expand_sweep_axis(self, command, target, arg_tokens, sweep_axis_list, sweep_string=""):
        util.debug(f"Entering expand_sweep_axis: command={command}, target={target}, arg_tokens={arg_tokens}, sweep_axis_list={sweep_axis_list}")
        if len(sweep_axis_list) == 0:
            # we aren't sweeping anything, create one job
            snapshot_name = target.replace('../','').replace('/','_') + sweep_string
            self.jobs.append({ 'name' : snapshot_name,
                               'command_list' : (['python3', os.path.realpath(__file__), command, target, '--job-name', snapshot_name] + arg_tokens)})
            return
        sweep_axis = sweep_axis_list[0]
        v = sweep_axis['from']
        while v < (sweep_axis['to'] + (sweep_axis['step']/2)):
            this_arg_tokens = []
            for a in arg_tokens:
                this_arg_tokens.append(a.replace(sweep_axis['key'], f"{v}"))
            next_sweep_axis_list = []
            if len(sweep_axis_list)>1:
                next_sweep_axis_list = sweep_axis_list[1:]
            v_string = f"{v}".replace('.','p')
            if v_string.endswith('p0'): v_string=v_string.replace('p0','')
            self.expand_sweep_axis(command, target, this_arg_tokens, next_sweep_axis_list, sweep_string+f"_{sweep_axis['key']}_{v_string}")
            v += sweep_axis['step']

class CommandFList(CommandDesign):
    def __init__(self, config):
        CommandDesign.__init__(self, config, "flist")
        self.args['out'] = "flist.out"
        self.args['emit-define'] = True
        self.args['emit-incdir'] = True
        self.args['emit-v'] = True
        self.args['emit-sv'] = True
        self.args['emit-vhd'] = True
        self.args['prefix-define'] = "+define+"
        self.args['prefix-incdir'] = "+incdir+"
        self.args['prefix-v'] = ""
        self.args['prefix-sv'] = ""
        self.args['prefix-vhd'] = ""
        self.args['single-quote-define'] = False
        self.args['quote-define'] = True
        self.args['xilinx'] = False # we don't want --xilinx to error, but it doesn't do anything much
        self.args['build-script'] = "" # we don't want this to error either

    def process_tokens(self, tokens, process_all=True):
        CommandDesign.process_tokens(self, tokens, process_all)
        self.do_it()

    def do_it(self):
        # add defines for this job
        self.set_tool_defines()
        if (self.args['top'] != ""):
            if os.path.exists(self.args['out']):
                if self.args['force']:
                    util.info(f"Removing existing {self.args['out']}")
                    os.remove(self.args['out'])
                else:
                    util.error(f"Not overwriting {self.args['out']} unless you specify --force")
            util.debug(f"Opening {self.args['out']} for writing")
            with open( self.args['out'] , 'w' ) as fo:
                if self.args['emit-define']:
                    for d in self.defines:
                        if self.defines[d] == None:
                            print(f"{self.args['prefix-define']}{d}", file=fo)
                        else:
                            if self.args['single-quote-define'] : quote = '\''
                            elif self.args['quote-define'] : quote = '"'
                            else : quote = ''
                            print(f"{self.args['prefix-define']}{quote}{d}={self.defines[d]}{quote}", file=fo)
                if self.args['emit-incdir']:
                    for i in self.incdirs:
                        print(f"{self.args['prefix-incdir']}{i}", file=fo)
                if self.args['emit-v']:
                    for f in self.files_v:
                        print(f"{self.args['prefix-v']}{f}", file=fo)
                if self.args['emit-sv']:
                    for f in self.files_sv:
                        print(f"{self.args['prefix-sv']}{f}", file=fo)
                if self.args['emit-vhd']:
                    for f in self.files_vhd:
                        print(f"{self.args['prefix-vhd']}{f}", file=fo)
            util.info(f"Created {self.args['out']}")

class CommandWaves(CommandDesign):
    def __init__(self, config):
        Command.__init__(self, config, "waves")

    def process_tokens(self, tokens, process_all=True):
        wave_file = None
        wave_dirs = []
        while len(tokens):
            # see if it's a flag/option like --debug, --seed <n>, etc
            if Command.process_tokens(self, tokens, process_all=False):
                continue
            if os.path.isfile(tokens[0]):
                if (wave_file != None):
                    util.error(f"Was already given wave file {wave_file}, not sure what to do with {tokens[0]}")
                wave_file = os.path.abspath(tokens[0])
                tokens.pop(0)
                continue
            if os.path.isdir(tokens[0]):
                if (wave_file != None):
                    util.error(f"Was already given wave file {wave_file}, not sure what to do with {tokens[0]}")
                wave_dirs.append(tokens[0])
            util.error("Didn't understand command token: '%s' in CommandWaves" % (tokens[0]))
        if not wave_file:
            util.info(f"need to look for wave file")
            # we weren't given a wave file, so we will look for one!
            if (len(wave_dirs) == 0) and os.path.isdir(self.args['eda-dir']):
                wave_dirs.append(self.args['eda-dir'])
            if (len(wave_dirs) == 0):
                wave_dirs.append(self.args['.'])
            all_files = []
            for d in wave_dirs:
                util.info(f"Looking for wavedumps below: {d}")
                for root, dirs, files in os.walk(d):
                    for f in files:
                        for e in [ '.wdb', '.vcd' ]:
                            if f.endswith(e):
                                util.info(f"Found wave file: {os.path.join(root,f)}")
                                all_files.append(os.path.join(root,f))
            if len(all_files) > 1:
                all_files.sort(key=lambda f: os.path.getmtime(f))
                util.info(f"Choosing: {self.args['file']} (newest)")
            if len(all_files):
                wave_file = all_files[-1]
            else:
                util.error(f"Couldn't find any wave files below: {','.join(wave_dirs)}")

        wave_file = os.path.abspath(wave_file)
        util.info(f"decided on opening: {wave_file}")
        tcl_name = wave_file + '.waves.tcl'
        with open( tcl_name,'w') as fo :
            print( 'current_fileset', file=fo)
            print( 'open_wave_database %s' % wave_file, file=fo)

        command_list = ['vivado', '-source', tcl_name]
        self.exec(os.path.dirname(wave_file), command_list)

class CommandUpload(CommandDesign):
    def __init__(self, config):
        Command.__init__(self, config, "upload")

    def process_tokens(self, tokens, process_all=True):
        Command.process_tokens(self, tokens, process_all)
        self.create_work_dir()
        self.do_it()

class CommandOpen(CommandDesign):
    def __init__(self, config):
        Command.__init__(self, config, "open")

    def process_tokens(self, tokens, process_all=True):
        Command.process_tokens(self, tokens, process_all)
        self.do_it()

class ToolVivado:
    def __init__(self):
        self.vivado_year = None
        self.vivado_release = None
        self.args['xilinx'] = False
        self.args['part'] = "xcu200-fsgd2104-2-e"

    def get_versions(self):
        if self.vivado_year != None:
            return
        vivado_path = shutil.which('vivado')
        if vivado_path == None:
            util.error("Vivado not in path, need to setup (i.e. source /opt/Xilinx/Vivado/2022.2/settings64.sh")
        util.debug("vivado_path = %s" % vivado_path)
        m = re.search(r'(\d\d\d\d)\.(\d)', vivado_path)
        if m:
            self.vivado_year = int(m.group(1))
            self.vivado_release = int(m.group(2))
            self.vivado_version = float(m.group(1)+"."+m.group(2))
            return
        util.error("Vivado path doesn't specificy version, expecting (dddd.d)")

    # we wait to call this as part of do_it because we only want to run all this after all options
    # have been processed, as things like --xilinx will affect the defines.  Maybe it should be
    # broken into a tool vs library phase, but likely command line opts can also affect tools...
    def set_tool_defines(self):
        # Will only be called from an object which also inherits from CommandDesign, i.e. has self.defines
        self.get_versions()
        self.defines['OC_TOOL_VIVADO'] = None
        self.defines['OC_TOOL_VIVADO_%4d_%d' % (self.vivado_year, self.vivado_release)] = None
        if self.args['xilinx']:
            self.defines['OC_LIBRARY_ULTRASCALE_PLUS'] = None
            self.defines['OC_LIBRARY'] = "1"
        else:
            self.defines['OC_LIBRARY_BEHAVIORAL'] = None
            self.defines['OC_LIBRARY'] = "0"
        # Code can be conditional on Vivado versions and often keys of "X or newer", "X or older", ...
        if (self.vivado_version <= 2021.1): self.defines['OC_TOOL_VIVADO_2021_1_OR_OLDER'] = None
        if (self.vivado_version <= 2021.2): self.defines['OC_TOOL_VIVADO_2021_2_OR_OLDER'] = None
        if (self.vivado_version <= 2022.1): self.defines['OC_TOOL_VIVADO_2022_1_OR_OLDER'] = None
        if (self.vivado_version <= 2022.2): self.defines['OC_TOOL_VIVADO_2022_2_OR_OLDER'] = None
        if (self.vivado_version <= 2023.1): self.defines['OC_TOOL_VIVADO_2023_1_OR_OLDER'] = None
        if (self.vivado_version <= 2023.2): self.defines['OC_TOOL_VIVADO_2023_2_OR_OLDER'] = None
        if (self.vivado_version >= 2021.1): self.defines['OC_TOOL_VIVADO_2021_1_OR_NEWER'] = None
        if (self.vivado_version >= 2021.2): self.defines['OC_TOOL_VIVADO_2021_2_OR_NEWER'] = None
        if (self.vivado_version >= 2022.1): self.defines['OC_TOOL_VIVADO_2022_1_OR_NEWER'] = None
        if (self.vivado_version >= 2022.2): self.defines['OC_TOOL_VIVADO_2022_2_OR_NEWER'] = None
        if (self.vivado_version >= 2023.1): self.defines['OC_TOOL_VIVADO_2023_1_OR_NEWER'] = None
        if (self.vivado_version >= 2023.2): self.defines['OC_TOOL_VIVADO_2023_2_OR_NEWER'] = None
        # Our first tool workaround.  Older Vivado's don't correctly compare types in synthesis (sim seems OK, argh)
        if (self.vivado_version < 2023.2): self.defines['OC_TOOL_BROKEN_TYPE_COMPARISON'] = None
        util.debug(f"Setup tool defines: {self.defines}")

class CommandSimVivado(CommandSim, ToolVivado):
    def __init__(self, config):
        CommandSim.__init__(self, config)
        ToolVivado.__init__(self)
        # add args specific to this simulator
        self.args['gui'] = False
        self.args['tcl-file'] = "sim.tcl"

    def do_it(self):
        # add defines for this job
        self.set_tool_defines()

        # compile verilog
        if len(self.files_v) or self.args['xilinx']:
            command_list = [ 'xvlog' ]
            if util.args['verbose']: command_list += ['-v', '2']
            if self.args['xilinx']:
                command_list += [ os.path.join( os.environ['XILINX_VIVADO'], 'data/verilog/src/glbl.v') ]
            for value in self.incdirs:
                command_list.append('-i')
                command_list.append(value)
            for key in self.defines.keys():
                value = self.defines[key]
                command_list.append('-d')
                if value == None:    command_list.append(key)
                elif "\'" in value:  command_list.append("\"%s=%s\"" % (key, value))
                else:                command_list.append("\'%s=%s\'" % (key, value))
            command_list += self.files_v
            self.exec(self.args['work-dir'], command_list)

        # compile systemverilog
        if len(self.files_sv):
            command_list = [ 'xvlog' ]
            command_list.append('-sv')
            if util.args['verbose']: command_list += ['-v', '2']
            for value in self.incdirs:
                command_list.append('-i')
                command_list.append(value)
            for key in self.defines.keys():
                value = self.defines[key]
                command_list.append('-d')
                if value == None:    command_list.append(key)
                elif "\'" in value:  command_list.append("\"%s=%s\"" % (key, value))
                else:                command_list.append("\'%s=%s\'" % (key, value))
            command_list += self.files_sv
            self.exec(self.args['work-dir'], command_list)

        # elab into snapshot
        command_list = [ 'xelab' ]
        command_list += [ self.args['top'], '-s', 'snapshot', '-timescale', '1ns/1ps', '--stats' ]
        if self.args['gui'] and self.args['waves']: command_list += ['-debug', 'all']
        elif self.args['gui']: command_list += ['-debug', 'typical']
        elif self.args['waves']: command_list += ['-debug', 'wave']
        if util.args['verbose']: command_list += ['-v', '2']
        if self.args['xilinx']:
            command_list += "-L xil_defaultlib -L unisims_ver -L unimacro_ver -L xpm -L secureip -L xilinx_vip".split(" ")
            command_list += ['glbl']
        self.exec(self.args['work-dir'], command_list)

        # check if we're bailing out early
        if self.stop_after_compile: return

        # create TCL
        tcl_name = os.path.abspath(os.path.join(self.args['work-dir'], self.args['tcl-file']))
        with open( tcl_name, 'w' ) as fo:
            if self.args['waves']:
                if self.args['waves-start']:
                    print("run %d ns" % self.args['waves-start'], file=fo)
                print("log_wave -recursive *", file=fo)
            print("run -all", file=fo)
            if not self.args['gui']:
                print("exit", file=fo)

        # execute snapshot
        command_list = [ 'xsim' ]
        if self.args['gui']: command_list += ['-gui']
        command_list += ['snapshot', '--stats', '--tclbatch', tcl_name, "--onerror", "quit"]
        self.exec(self.args['work-dir'], command_list)

        if self.args['pass-pattern'] != "":
            # we've been asked to scan the logfile for a pass signature, else exit with error code
            passed = False
            with open(os.path.join(self.args['work-dir'],"xsim.log"), "r") as f:
                for line in f:
                    if self.args['pass-pattern'] in line:
                        passed = True
                        break
            if not passed:
                util.error(f"Didn't get passing pattern: '{self.args['pass-pattern']}' in '{os.path.join(self.args['work-dir'],'xsim.log')}'")

class CommandElabVivado(CommandSimVivado):
    def __init__(self, config):
        CommandSimVivado.__init__(self, config)
        # add args specific to this simulator
        self.stop_after_compile = True

class CommandSynthVivado(CommandSynth, ToolVivado):
    def __init__(self, config):
        CommandSynth.__init__(self, config)
        ToolVivado.__init__(self)
        # add args specific to this simulator
        self.args['gui'] = False
        self.args['tcl-file'] = "synth.tcl"
        self.args['xdc'] = ""

    def do_it(self):
        # add defines for this job
        self.set_tool_defines()

        # create TCL
        tcl_file = os.path.abspath(os.path.join(self.args['work-dir'], self.args['tcl-file']))
        v = ""
        if util.args['verbose']: v += " -verbose"
        elif util.args['quiet']: v += " -quiet"
        defines = ""
        for key in self.defines.keys():
            value = self.defines[key]
            defines += (f"-verilog_define {key}" + (" " if value == None else f"={value} "))
        incdirs = ""
        if len(self.incdirs):
            incdirs = " -include_dirs "+";".join(self.incdirs)
        flatten = ""
        if self.args['flatten-all']:    flatten = "-flatten_hierarchy full"
        elif self.args['flatten-none']: flatten = "-flatten_hierarchy none"
        with open( tcl_file, 'w' ) as fo:
            for f in self.files_v:     print(f"read_verilog {f}", file=fo)
            for f in self.files_sv:    print(f"read_verilog -sv {f}", file=fo)
            for f in self.files_vhd:   print(f"add_file {f}", file=fo)
            if self.args['xdc'] != "":
                default_xdc = False
                xdc_file = os.path.abspath(self.args['xdc'])
            else:
                default_xdc = True
                xdc_file = os.path.abspath(os.path.join(self.args['work-dir'], "default_constraints.xdc"))
                util.info(f"Creating default constraints: clock:{self.args['clock-ns']}ns, "+
                          f"idelay:{self.args['idelay-ns']}ns, odelay:{self.args['odelay-ns']}ns")
                with open( xdc_file, 'w' ) as ft:
                    print(f"create_clock -add -name clock -period {self.args['clock-ns']} [get_ports {{clock}}]", file=ft)
                    print(f"set_input_delay -max {self.args['idelay-ns']} -clock clock "+
                          f"[get_ports * -filter {{DIRECTION == IN && NAME !~ \"clock\"}}]", file=ft)
                    print(f"set_output_delay -max {self.args['odelay-ns']} -clock clock "+
                          f"[get_ports * -filter {{DIRECTION == OUT}}]", file=ft)
            print(f"create_fileset -constrset constraints_1 {v}", file=fo)
            print(f"add_files -fileset constraints_1 {xdc_file} {v}", file=fo)
            print(f"# FIRST PASS -- auto_detect_xpm", file=fo)
            print(f"synth_design -rtl -rtl_skip_ip -rtl_skip_constraints -no_timing_driven -no_iobuf "+
                  f"-top {self.args['top']} {incdirs} {defines} {v}", file=fo)
            print(f"auto_detect_xpm {v}", file=fo)
            print(f"synth_design -no_iobuf -part {self.args['part']} {flatten} -constrset constraints_1 "+
                  f"-top {self.args['top']} {incdirs} {defines} {v}", file=fo)
            print(f"write_verilog -force {self.args['top']}.vg {v}", file=fo)
            print(f"report_utilization -file {self.args['top']}.flat.util.rpt {v}", file=fo)
            print(f"report_utilization -file {self.args['top']}.hier.util.rpt {v} -hierarchical -hierarchical_depth 20", file=fo)
            print(f"report_timing -file {self.args['top']}.timing.rpt {v}", file=fo)
            print(f"report_timing_summary -file {self.args['top']}.summary.timing.rpt {v}", file=fo)
            print(f"report_timing -from [all_inputs] -file {self.args['top']}.input.timing.rpt {v}", file=fo)
            print(f"report_timing -to [all_outputs] -file {self.args['top']}.output.timing.rpt {v}", file=fo)
            print(f"report_timing -from [all_inputs] -to [all_outputs] -file {self.args['top']}.through.timing.rpt {v}", file=fo)
            print(f"set si [get_property -quiet SLACK [get_timing_paths -max_paths 1 -nworst 1 -setup -from [all_inputs]]]", file=fo)
            print(f"set so [get_property -quiet SLACK [get_timing_paths -max_paths 1 -nworst 1 -setup -to [all_outputs]]]", file=fo)
            print(f"set_false_path -from [all_inputs] {v}", file=fo)
            print(f"set_false_path -to [all_outputs] {v}", file=fo)
            print(f"set sf [get_property -quiet SLACK [get_timing_paths -max_paths 1 -nworst 1 -setup]]", file=fo)
            print(f"if {{ ! [string is double -strict $sf] }} {{ set sf 9999 }}", file=fo)
            print(f"if {{ ! [string is double -strict $si] }} {{ set si 9999 }}", file=fo)
            print(f"if {{ ! [string is double -strict $so] }} {{ set so 9999 }}", file=fo)
            print(f"puts \"\"", file=fo)
            print(f"puts \"*** ****************** ***\"", file=fo)
            print(f"puts \"***                    ***\"", file=fo)
            print(f"puts \"*** SYNTHESIS COMPLETE ***\"", file=fo)
            print(f"puts \"***                    ***\"", file=fo)
            print(f"puts \"*** ****************** ***\"", file=fo)
            print(f"puts \"\"", file=fo)
            print(f"puts \"** AREA **\"", file=fo)
            print(f"report_utilization -hierarchical", file=fo)
            print(f"puts \"** TIMING **\"", file=fo)
            print(f"puts \"\"", file=fo)
            if default_xdc:
                print(f"puts \"(Used default XDC: {xdc_file})\"", file=fo)
                print(f"puts \"DEF CLOCK NS  : [format %.3f {self.args['clock-ns']}]\"", file=fo)
                print(f"puts \"DEF IDELAY NS : [format %.3f {self.args['idelay-ns']}]\"", file=fo)
                print(f"puts \"DEF ODELAY NS : [format %.3f {self.args['odelay-ns']}]\"", file=fo)
            else:
                print(f"puts \"(Used provided XDC: {xdc_file})\"", file=fo)
            print(f"puts \"\"", file=fo)
            print(f"puts \"F2F SLACK     : [format %.3f $sf]\"", file=fo)
            print(f"puts \"INPUT SLACK   : [format %.3f $si]\"", file=fo)
            print(f"puts \"OUTPUT SLACK  : [format %.3f $so]\"", file=fo)
            print(f"puts \"\"", file=fo)

        # execute Vivado
        command_list = [ 'vivado', '-mode', 'batch', '-source', tcl_file, '-log', f"{self.args['top']}.synth.log" ]
        if not util.args['verbose']: command_list.append('-notrace')
        self.exec(self.args['work-dir'], command_list)

class CommandProjVivado(CommandProj, ToolVivado):
    def __init__(self, config):
        CommandProj.__init__(self, config)
        ToolVivado.__init__(self)
        # add args specific to this simulator
        self.args['gui'] = True
        self.args['oc-vivado-tcl'] = True
        self.args['tcl-file'] = "proj.tcl"
        self.args['xdc'] = ""
        self.args['board'] = ""

    def do_it(self):
        # add defines for this job
        self.set_tool_defines()

        # create TCL
        tcl_file = os.path.abspath(os.path.join(self.args['work-dir'], self.args['tcl-file']))
        v = ""
        if util.args['verbose']: v += " -verbose"
        elif util.args['quiet']: v += " -quiet"

        with open( tcl_file, 'w' ) as fo:

            print(f"create_project {self.args['top']}_proj {self.args['work-dir']} {v}", file=fo)

            oc_root = util.get_oc_root()
            if self.args['oc-vivado-tcl'] and oc_root:
                print(f"source \"{oc_root}/boards/vendors/xilinx/oc_vivado.tcl\" -notrace", file=fo)
            if self.args['board'] != "":
                print(f"set_property board_part {self.args['board']} [current_project]", file=fo)

            incdirs = " ".join(self.incdirs)
            defines = ""
            for key in self.defines.keys():
                value = self.defines[key]
                defines += (f"{key} " if value == None else f"{key}={value} ")

            print(f"set_property include_dirs {{{incdirs}}} [get_filesets sources_1]", file=fo)
            print(f"set_property include_dirs {{{incdirs}}} [get_filesets sim_1]", file=fo)
            print(f"set_property verilog_define {{{defines}}} [get_filesets sources_1]", file=fo)
            print(f"set_property verilog_define {{SIMULATION {defines}}} [get_filesets sim_1]", file=fo)

            print(f"set_property -name {{STEPS.SYNTH_DESIGN.ARGS.MORE OPTIONS}} -value {{-verilog_define SYNTHESIS}} "+
                  f"-objects [get_runs synth_1]", file=fo)
            print(f"set_property {{xsim.simulate.runtime}} {{10ms}} [get_filesets sim_1]", file=fo)
            print(f"set_property {{xsim.simulate.log_all_signals}} {{true}} [get_filesets sim_1]", file=fo)

            for f in self.files_v + self.files_sv + self.files_vhd:
                if f.find("/sim/") >= 0: fileset = "sim_1"
                elif f.find("/tests/") >= 0: fileset = "sim_1"
                else: fileset = "sources_1"
                print(f"add_files -norecurse {f} -fileset [get_filesets {fileset}]", file=fo)

        # execute Vivado
        command_list = [ 'vivado', '-mode', 'gui', '-source', tcl_file, '-log', f"{self.args['top']}.proj.log" ]
        if not util.args['verbose']: command_list.append('-notrace')
        self.exec(self.args['work-dir'], command_list)
        util.info(f"Synthesis done, results are in: {self.args['work-dir']}")

class CommandBuildVivado(CommandBuild, ToolVivado):
    def __init__(self, config):
        CommandBuild.__init__(self, config)
        ToolVivado.__init__(self)
        # add args specific to this simulator
        self.args['gui'] = False

    def do_it(self):
        # add defines for this job
        self.set_tool_defines()

        # create FLIST
        flist_file = os.path.join(self.args['work-dir'],'build.flist')
        command_list = ['python3', os.path.realpath(__file__), 'flist', self.args['top-path'],
                        '--force',
                        '--xilinx',
                        '--out', flist_file,
                        '--no-emit-incdir',
                        '--no-quote-define',
                        '--prefix-define', '"oc_set_project_define "',
                        '--prefix-sv', '"add_files -norecurse "',
                        '--prefix-v', '"add_files -norecurse "',
                        '--prefix-vhd', '"add_files -norecurse "']
        self.exec(cwd, command_list)

        print(f"debug: {self.args}")
        project_dir = 'project.'+self.args['job-name']

        # launch Vivado
        command_list = ['vivado']
        command_list += ['-mode', 'gui' if self.args['gui'] else 'batch' ]
        command_list += ['-log', os.path.join(self.args['work-dir'], self.args['top']+'.build.log') ]
        if not util.args['verbose']: command_list.append('-notrace')
        command_list += ['-source', self.args['build-script'] ]
        command_list += ['-tclargs', project_dir, flist_file] # these must come last, all after -tclargs get passed to build-script
        self.exec(cwd, command_list)

        util.info(f"Build done, results are in: {self.args['work-dir']}")

class CommandFListVivado(CommandFList, ToolVivado):
    def __init__(self, config):
        CommandFList.__init__(self, config)
        ToolVivado.__init__(self)

class CommandUploadVivado(CommandUpload, ToolVivado):
    def __init__(self, config):
        CommandUpload.__init__(self, config)
        ToolVivado.__init__(self)
        # add args specific to this simulator
        self.args['gui'] = False
        self.args['file'] = False
        self.args['usb'] = True
        self.args['host'] = "localhost"
        self.args['port'] = 3121
        self.args['target'] = 0
        self.args['tcl-file'] = "upload.tcl"

    def do_it(self):
        if self.args['file'] == False:
            util.info(f"Searching for bitfiles...")
            found_file = False
            all_files = []
            for root, dirs, files in os.walk("."):
                for file in files:
                    if file.endswith(".bit"):
                        found_file = os.path.abspath(os.path.join(root,file))
                        util.info(f"Found bitfile: {found_file}")
                        all_files.append(found_file)
            self.args['file'] = found_file
        if len(all_files) > 1:
            all_files.sort(key=lambda f: os.path.getmtime(f))
            self.args['file'] = all_files[-1]
            util.info(f"Choosing: {self.args['file']} (newest)")
        if self.args['file'] == False:
            util.error(f"Couldn't find a bitfile to upload")
        if self.args['usb']:
            util.info(f"Uploading bitfile: {self.args['file']}")
            util.info(f"Uploading via {self.args['host']}:{self.args['port']} USB target #{self.args['target']}")
            self.upload_usb_jtag(self.args['host'], self.args['port'], self.args['target'], self.args['file'])
        else:
            util.error(f"Only know how to upload via USB for now")

    def upload_usb_jtag(self, host, port, target, bit_file):
        # create TCL
        tcl_file = os.path.abspath(os.path.join(self.args['work-dir'], self.args['tcl-file']))
        ltx_file = os.path.splitext(bit_file)[0] + ".ltx"
        if not os.path.exists(ltx_file):
            ltx_file = False

        with open( tcl_file, 'w' ) as fo:
            print(f"open_hw", file=fo)
            print(f"connect_hw_server -url {host}:{port}", file=fo)
            print(f"refresh_hw_server -force_poll", file=fo)
            print(f"set hw_targets [get_hw_targets */xilinx_tcf/Xilinx/*]", file=fo)
            print(f"if {{ [llength $hw_targets] <= {target} }} {{", file=fo)
            print(f"  puts \"ERROR: There is no target number {target}\"", file=fo)
            print(f"}}", file=fo)
            print(f"current_hw_target [lindex $hw_targets {target}]", file=fo)
            print(f"open_hw_target", file=fo)
            print(f"refresh_hw_target", file=fo)
            print(f"current_hw_device [lindex [get_hw_devices] 0]", file=fo)
            print(f"refresh_hw_device [current_hw_device]", file=fo)
            print(f"set_property PROGRAM.FILE {bit_file} [current_hw_device]", file=fo)
            if ltx_file:
                print(f"set_property PROBES.FILE {ltx_file} [current_hw_device]", file=fo)
            print(f"program_hw_devices [current_hw_device]", file=fo)
            if self.args['gui']:
                print(f"refresh_hw_device [current_hw_device]", file=fo)
                print(f"display_hw_ila_data [ get_hw_ila_data hw_ila_data_1 -of_objects [get_hw_ilas] ]", file=fo)
            else:
                print(f"close_hw_target", file=fo)
                print(f"exit", file=fo)

        # execute Vivado
        command_list = [ 'vivado', '-source', tcl_file, '-log', f"fpga.upload.log" ]
        if not self.args['gui']:
            command_list.append('-mode')
            command_list.append('batch')
        self.exec(self.args['work-dir'], command_list)

class CommandOpenVivado(CommandOpen, ToolVivado):
    def __init__(self, config):
        CommandOpen.__init__(self, config)
        ToolVivado.__init__(self)
        # add args specific to this simulator
        self.args['gui'] = True
        self.args['file'] = False

    def do_it(self):
        if self.args['file'] == False:
            util.info(f"Searching for project...")
            found_file = False
            all_files = []
            for root, dirs, files in os.walk("."):
                for file in files:
                    if file.endswith(".xpr"):
                        found_file = os.path.abspath(os.path.join(root,file))
                        util.info(f"Found project: {found_file}")
                        all_files.append(found_file)
            self.args['file'] = found_file
        if len(all_files) > 1:
            all_files.sort(key=lambda f: os.path.getmtime(f))
            self.args['file'] = all_files[-1]
            util.info(f"Choosing: {self.args['file']} (newest)")
        if self.args['file'] == False:
            util.error(f"Couldn't find an XPR Vivado project to open")
        projname = os.path.splitext(os.path.basename(self.args['file']))[0]
        projdir = os.path.dirname(self.args['file'])
        oc_root = util.get_oc_root()
        oc_vivado_tcl = os.path.join(oc_root, 'boards', 'vendors', 'xilinx', 'oc_vivado.tcl')
        command_list = [ 'vivado', '-source', oc_vivado_tcl, '-log', f"{projname}.open.log", self.args['file'] ]
        self.exec(projdir, command_list)


class ToolQuesta:
    def __init__(self):
        self.questa_major = None
        self.questa_minor = None
        self.args['xilinx'] = False
        self.args['part'] = "xcu200-fsgd2104-2-e"

    def get_versions(self):
        if self.questa_major != None:
            return
        qrun_path = shutil.which('qrun')
        if qrun_path == None:
            util.error("qrun not in path, need to setup (i.e. source /opt/intelFPGA_pro/23.4/settings64.sh")
        util.debug("qrun_path = %s" % qrun_path)
        m = re.search(r'(\d+)\.(\d+)', qrun_path)
        if m:
            self.questa_minor = int(m.group(1))
            self.questa_major = int(m.group(2))
            return
        util.error("Questa path doesn't specificy version, expecting (d+.d+)")

    def set_tool_defines(self):
        # Will only be called from an object which also inherits from CommandDesign, i.e. has self.defines
        self.get_versions()
        self.defines['OC_TOOL_QUESTA'] = None
        self.defines['OC_TOOL_QUESTA_%d_%d' % (self.questa_major, self.questa_minor)] = None
        if self.args['xilinx']:
            self.defines['OC_LIBRARY_ULTRASCALE_PLUS'] = None
            self.defines['OC_LIBRARY'] = "1"
        else:
            self.defines['OC_LIBRARY_BEHAVIORAL'] = None
            self.defines['OC_LIBRARY'] = "0"

class CommandSimQuesta(CommandSim, ToolQuesta):
    def __init__(self, config):
        CommandSim.__init__(self, config)
        ToolQuesta.__init__(self)
        # add args specific to this simulator
        self.args['gui'] = False
        self.args['tcl-file'] = "sim.tcl"

    def do_it(self):
        # add defines for this job
        self.set_tool_defines()

        # it all gets done with one command
        command_list = [ 'qrun', "-64", "-sv" ]

        # incdirs
        for value in self.incdirs:
            command_list += [ f"+incdir+{value}" ]

        # defines
        for key in self.defines.keys():
            value = self.defines[key]
            if value == None:
                command_list += [ f"+define+{key}" ]
            else:
                command_list += [ f"\'+define+{key}={value}\'" ]

        # compile verilog
        for f in self.files_v:
            command_list += [ f ]

        # compile systemverilog
        for f in self.files_sv:
            command_list += [ f ]

        if self.args['xilinx']:
            if 'XILINX_VIVADO' not in os.environ:
                util.error("Vivado is not setup, no XILINX_VIVADO in env")
            command_list += [ os.path.join( os.environ['XILINX_VIVADO'], 'data/verilog/src/glbl.v') ]

        # misc options
        command_list += [ '-top', self.args['top'], '-timescale', '1ns/1ps', '-work', 'work.lib']
        if self.args['gui'] and self.args['waves']: command_list += ['-debug', 'all']
        elif self.args['gui']: command_list += ['-debug', 'typical']
        elif self.args['waves']: command_list += ['-debug', 'wave']
        if util.args['verbose']: command_list += ['-verbose']
        if self.args['xilinx']:
            command_list += "-L xil_defaultlib -L unisims_ver -L unimacro_ver -L xpm -L secureip -L xilinx_vip".split(" ")

        # check if we're bailing out early
        if self.stop_after_compile:
            command_list += ['-elab', 'elab.output', '-do', '"quit"' ]

        # execute snapshot
        if self.args['gui']: command_list += ['-gui=interactive']
        self.exec(self.args['work-dir'], command_list)

        #temp
        return

        # create TCL -- move this up
        tcl_name = os.path.abspath(os.path.join(self.args['work-dir'], self.args['tcl-file']))
        with open( tcl_name, 'w' ) as fo:
            if self.args['waves']:
                if self.args['waves-start']:
                    print("run %d ns" % self.args['waves-start'], file=fo)
                print("log_wave -recursive *", file=fo)
            print("run -all", file=fo)
            if not self.args['gui']:
                print("exit", file=fo)

class CommandElabQuesta(CommandSimQuesta):
    def __init__(self, config):
        CommandSimQuesta.__init__(self, config)
        # add args specific to this simulator
        self.stop_after_compile = True

# ****************************************************************************************************
# MAIN

config = {
    'command_handler' : {
        "sim"    : CommandSim,
        "elab"   : CommandElab,
        "synth"  : CommandSynth,
        "flist"  : CommandFList,
        "proj"   : CommandProj,
        "multi"  : CommandMulti,
        "sweep"  : CommandSweep,
        "build"  : CommandBuild,
        "waves"  : CommandWaves,
        "upload" : CommandUpload,
        "open"   : CommandOpen,
    },
    'defines'        : {},
    'dep_sub'        : [ [ r'csr\@(\w+)\.txt', r'\1.sv@csrgen,\1.txt $root_dir/v_csr_regs_deps'], ],
    # TODO: I don't think we want file_order stuff.  Anyway how do you handle a package pulling in another package.
    # best if we keep files in the order declared via DEPS and require that you include packages before dependent source
    # OR require that packages are `included?
    'file_order'     : [ [ r'\S+_pkg\.sv', -100 ], ],
    'vars'           : { 'root_dir' : os.path.abspath(util.getcwd()) },
}

def usage(tokens = []):
    if len(tokens)==0:
        print(
"""
    Usage: eda <command> <options> <targets>

    Where <command> is one of:

    sim          - Simulates a DEPS target
    elab         - Elaborates a DEPS target (sort of sim based LINT)
    synth        - Synthesizes a DEPS target
    flist        - Create dependency from a DEPS target
    proj         - Create a project from a DEPS target for GUI sim/waves/debug
    multi        - Run multiple DEPS targets, serially or in parallel
    sweep        - Sweep one or more arguments across a range, serially or in parallel
    build        - Build for a board, creating a project and running build flow
    waves        - Opens waveform from prior simulation
    upload       - Uploads a finished design into hardware
    open         - Opens a project
    help         - This help (without args), or i.e. "eda help sim" for specific help
""")
    elif tokens[0] in config['command_handler']:
        sco = config['command_handler'][tokens[0]](config) # sub command object
        sco.help()
        util.exit()
    else:
        util.info(f"Valid commands are: ")
        for k in sorted(config['command_handler'].keys()):
            util.info(f"   {k:20}")
        util.error(f"Cannot provide help, don't understand command: '{tokens[0]}'")

def interactive():
    read_file = False
    while True:
        if read_file:
            line = f.readline()
            if line:
                print("%s->%s" % (fname, line), end="")
            else:
                read_file = False
                f.close()
                continue
        else:
            line = input('EDA->')
        m = re.match(r'^([^\#]*)\#.*$', line)
        if m: line = m.group(1)
        tokens = line.split()
        process_tokens(tokens)

def auto_tool_setup():
    if shutil.which('vivado'):
        util.info(f"Detected Vivado ({shutil.which('vivado')}), auto-setting up tool (--tool vivado)")
        tool_setup('vivado', quiet=True)
    if shutil.which('qrun'):
        util.info(f"Detected Questa ({shutil.which('qrun')}), auto-setting up tool (--tool questa)")
        tool_setup('questa', quiet=True)

def tool_setup(tool, quiet=False):
    global tools_loaded
    if tool == "vivado":
        config['command_handler']['elab'] = CommandElabVivado
        config['command_handler']['sim'] = CommandSimVivado
        config['command_handler']['synth'] = CommandSynthVivado
        config['command_handler']['proj'] = CommandProjVivado
        config['command_handler']['upload'] = CommandUploadVivado
        config['command_handler']['open'] = CommandOpenVivado
        config['command_handler']['flist'] = CommandFListVivado
        config['command_handler']['build'] = CommandBuildVivado
    elif tool == "questa":
        config['command_handler']['elab'] = CommandElabQuesta
        config['command_handler']['sim'] = CommandSimQuesta
    else:
        util.error(f"Don't know tool '{tool}'")
    if not quiet:
        util.info(f"Setup for tool: '{tool}'")
    tools_loaded.append(tool)

def process_tokens(tokens):
    # this is the top level token processing function.  tokens can come from command line, setup file, or interactively.
    # we do one pass through all the tokens, triaging them into:
    # - those we can execute immediate (help, quit, and global opens like --debug, --color)
    # - a command (sim, synth, etc)
    # - command arguments (--seed, +define, +incdir, etc) which will be deferred and processed by the command
    deferred_tokens = []
    command = ""
    while (len(tokens)):
        token = tokens.pop(0)
        if (token == 'quit') or (token == 'q') or (token == 'exit'):
            util.exit()
        if ((token == 'help') or (token == 'h') or
            (token == '-help') or (token == '-h') or
            (token == '--help') or (token == '--h')):
            usage(tokens)
            util.exit()
        if util.process_token(token): # see if eda_util needs to process this (printing related)
            continue
        if token == '--tool':
            if len(tokens) < 1: util.error("Need argument after '--tool'")
            tool_setup(tokens.pop(0))
            #exec("config['command_handler']['%s'] = %s" % (tokens[0], tokens[1]))
            #tokens.pop(0)
            continue
        if token in config['command_handler']:
            if (command == ""):
                command = token
                continue
        deferred_tokens.append(token)
    if command == "": util.error(f"Didn't get a command!")
    sco = config['command_handler'][command](config) # sub command object
    sco.process_tokens(deferred_tokens)

# **************************************************************
# **** Interrupt Handler

def signal_handler(sig, frame):
    util.fancy_stop()
    util.info('Received Ctrl+C...', start='\nINFO: [EDA] ')
    util.exit(-1)

# **************************************************************
# **** Startup Code

debug_respawn = False
#debug_respawn = True
util.progname = "EDA"

def main():
    if len(sys.argv)>1:
        # at some point lets use the name of the program to lookup a command translation.  then someone can
        # softlink say "isim" to "eda", and we translate that into "eda sim" which takes pretty standard
        # args just fine.  eventually define a translation layer for arguments to enable mapping features
        # when emulating the command line of other tools.
        auto_tool_setup()
        process_tokens(sys.argv[1:])
    else:
        util.info(f"*** OpenCOS EDA Wrapper ***")
        interactive() # go interactive if not given any arguments

if __name__ == '__main__':
    # First we check if we are respawning
    this_path = os.path.realpath(__file__)
    if debug_respawn: util.debug(f"RESPAWN: this_path : '{this_path}'")
    oc_root = util.get_oc_root()
    if debug_respawn: util.debug(f"RESPAWN: oc_root   : '{oc_root}'")
    cwd = util.getcwd()
    if debug_respawn: util.debug(f"RESPAWN: cwd       : '{cwd}'")
    if oc_root and (not '--no-respawn' in sys.argv):
        new_path = os.path.join(oc_root, 'bin', 'eda')
        if (this_path != new_path):
            # we are not the correct version of EDA for this Git repo, we should respawn
            util.info(f"{this_path} respawning {new_path} in {cwd} (use --no-spawn to avoid)")
            sys.argv[0] = new_path
            proc = subprocess.Popen(sys.argv, shell=0, cwd=cwd, universal_newlines=True)
            while True:
                try:
                    proc.communicate()
                    break
                except KeyboardInterrupt:
                    continue
            util.exit()
    signal.signal(signal.SIGINT, signal_handler)
    main()

# TODO:
# * read config from config files (script dir, home dir, cwd upwards to ... ? )

# IDEAS:
# * options with no default (i.e. if user doesn't override, THEN we set it, like "seed" or "work-dir") can be given a
#   special type (DefaultVar) versus saying "None" so that help can say more about it (it's a string, it's default val
#   is X, etc) and it can be queried as to whether it's really a default val.  This avoids having to avoid default vals
#   that user can never set (-1, None, etc) which make it hard to infer the type.  this same object can be given help
#   info and simply "render" to the expected type (str, integer, etc) when used.
